{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yWn-pJumWmU",
        "outputId": "9bb10919-88c7-4794-c9fb-406c75c4e4a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Charger un modèle Word2Vec pré-entraîné en anglais\n",
        "model = api.load(\"glove-wiki-gigaword-100\")  # 100 dimensions GloVe model\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Fonction de tokenisation et de filtrage des mots d'arrêt\n",
        "def preprocess(sentence):\n",
        "    tokens = word_tokenize(sentence.lower())\n",
        "    return [word for word in tokens if word.isalpha() and word not in stop_words]\n"
      ],
      "metadata": {
        "id": "SIMhcjcJmbx8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonction pour calculer le vecteur de contexte moyen\n",
        "def get_context_vector(words, target_index):\n",
        "    context_vectors = []\n",
        "    for i, word in enumerate(words):\n",
        "        if i != target_index and word in model:\n",
        "            context_vectors.append(model[word])\n",
        "    return np.mean(context_vectors, axis=0) if context_vectors else None\n",
        "\n",
        "# Fonction de détection des erreurs sémantiques\n",
        "def detect_typo_semantic_error(sentence, threshold=0.5):\n",
        "    words = preprocess(sentence)\n",
        "    errors = []\n",
        "\n",
        "    for i, word in enumerate(words):\n",
        "        if word not in model:\n",
        "            continue\n",
        "        context_vector = get_context_vector(words, i)\n",
        "        if context_vector is not None:\n",
        "            word_vector = model[word]\n",
        "            similarity = 1 - cosine(word_vector, context_vector)\n",
        "\n",
        "            # Si la similarité est inférieure au seuil, on considère qu'il y a une erreur\n",
        "            if similarity < threshold:\n",
        "                errors.append((word, similarity))\n",
        "\n",
        "    return errors\n"
      ],
      "metadata": {
        "id": "yAoSx6elmeVo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemples de phrases avec et sans erreurs sémantiques\n",
        "sentences = [\n",
        "    \"The cat sat on the mat.\",          # Pas d'erreur\n",
        "    \"The cat sat on the hat.\",          # Erreur (hat au lieu de mat)\n",
        "    \"I put a nice cat on my head.\",     # Erreur (head au lieu de hat)\n",
        "    \"She bought a book.\",               # Pas d'erreur\n",
        "    \"She bought a boot.\"                # Erreur (boot au lieu de book)\n",
        "]\n",
        "\n",
        "# Tester les phrases\n",
        "for sentence in sentences:\n",
        "    errors = detect_typo_semantic_error(sentence)\n",
        "    if errors:\n",
        "        print(f\"Erreur détectée dans la phrase: '{sentence}'\")\n",
        "        for word, similarity in errors:\n",
        "            print(f\" - Mot suspecté: '{word}' avec similarité {similarity:.2f}\")\n",
        "    else:\n",
        "        print(f\"Aucune erreur détectée dans la phrase: '{sentence}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbiNApvkmgFP",
        "outputId": "2e00ad79-53b0-4b72-da8c-5c1121bc2495"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erreur détectée dans la phrase: 'The cat sat on the mat.'\n",
            " - Mot suspecté: 'cat' avec similarité 0.24\n",
            " - Mot suspecté: 'sat' avec similarité 0.37\n",
            " - Mot suspecté: 'mat' avec similarité 0.32\n",
            "Erreur détectée dans la phrase: 'The cat sat on the hat.'\n",
            " - Mot suspecté: 'cat' avec similarité 0.46\n",
            " - Mot suspecté: 'sat' avec similarité 0.32\n",
            "Erreur détectée dans la phrase: 'I put a nice cat on my head.'\n",
            " - Mot suspecté: 'cat' avec similarité 0.47\n",
            "Erreur détectée dans la phrase: 'She bought a book.'\n",
            " - Mot suspecté: 'bought' avec similarité 0.39\n",
            " - Mot suspecté: 'book' avec similarité 0.39\n",
            "Erreur détectée dans la phrase: 'She bought a boot.'\n",
            " - Mot suspecté: 'bought' avec similarité 0.13\n",
            " - Mot suspecté: 'boot' avec similarité 0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mETjUlHWmkQe"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}